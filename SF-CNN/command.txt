command:
python3 SF_CNN_2fre_train.py > train1.log 2>&1
python3 SF_CNN_2fre_train_further.py > train2.log 2>&1
python3 SF_CNN_2fre_test.py > test.log 2>&1

GPU: NVIDIA GeForce RTX 3060 Ti
cuda: 12.3
cudnn: 8.9.7
tensorflow: 2.15.0
https://jackfrisht.medium.com/install-nvidia-driver-via-ppa-in-ubuntu-18-04-fc9a8c4658b9


CNN, epochs = 200, lr = 0.0001, batch_size = 128
SNR(dB)		NMSE
    -10		0.8902655945595724
     -5		0.5751199399355023
      0		0.36848606844546833
      5		0.29410193315144156
     10		0.2553683132455284
     15		0.23459051626799857
     20		0.2303461244047422
     
CNN, epochs = 200, lr = 0.0001, batch_size = 32
SNR(dB)		NMSE
    -10		0.810673524905295
     -5		0.4919532945371677
      0		0.2643258475639457
      5		0.16703036852743622
     10		0.11317730937141791
     15		0.09042117733683336
     20		0.07431391089906239
---------------------------------------------------------------------------------------------
Transformers(Encoder without positional encoding, (16 * 32 * 4)), epochs = 200, lr = 0.0001, batch_size = 32
SNR(dB)		NMSE
    -10		1.0034997822283107
     -5		1.0022078917963781
      0		0.42036374677900773
      5		0.24588232616118508
     10		0.13356168133422286
     15		0.08693595202165977
     20		0.055574757864449695
     
Transformers(Encoder without positional encoding, (4 * 16 * 32)), epochs = 200, lr = 0.0001, batch_size = 32
SNR(dB)		NMSE
    -10		1.0056178096656145
     -5		1.0051167132633074
      0		1.0047594643512026
      5		1.0135836603921828
     10		1.0049115998872755
     15		0.14973634341748948
     20		0.10742040065425469
     
Transformers(Encoder without positional encoding, (32 * 16 * 4)), epochs = 200, lr = 0.0001, batch_size = 32
SNR(dB)		NMSE
    -10		1.005581103661059
     -5		1.023077848010152
      0		1.0091059088906147
      5		1.0158015911275906
     10		0.13586349671622336
     15		0.0907570120291898
     20		0.052233937396309695
---------------------------------------------------------------------------------------------
Transformers(Encoder, (16 * 32 * 4)), epochs = 200, lr = 0.0001, batch_size = 32
SNR(dB)		NMSE
    -10		0.030377166345715523
     -5		0.020921865478157997
      0		0.01644887961447239
      5		0.013676438480615616
     10		0.012209874577820301
     15		0.01129317656159401
     20		0.011004100553691387
     
Transformers(Encoder, (4 * 16 * 32)), epochs = 200, lr = 0.0001, batch_size = 32
SNR(dB)		NMSE
    -10		0.035654228180646896
     -5		0.025894038379192352
      0		0.01961899921298027
      5		0.01625351794064045
     10		0.0141898263245821
     15		0.013078039512038231
     20		0.012580392882227898

Transformers(Encoder, (32 * 16 * 4)), epochs = 200, lr = 0.0001, batch_size = 32
SNR(dB)		NMSE
    -10		0.030933775007724762
     -5		0.021904414519667625
      0		0.016832156106829643
      5		0.013988425023853779
     10		0.012418906204402447
     15		0.011840230785310268
     20		0.011266968213021755

Transformers(Encoder, originnal shape), epochs = 200, lr = 0.0001, batch_size = 32
SNR(dB)		NMSE
    -10		0.11000585556030273
     -5		0.05076548457145691
      0		0.04574974998831749
      5		0.02721697837114334
     10		0.02782992459833622
     15		0.028809938579797745
     20		0.022801632061600685
---------------------------------------------------------------------------------------------
Transformers(Encoder * 4 + Decoder * 4, (16 * 32 * 4)), epochs = 200, lr = 0.0001, batch_size = 32
SNR(dB)		NMSE
    -10		0.030267110094428062
     -5		0.02098541334271431
      0		0.01601572334766388
      5		0.013475433923304081
     10		0.011958678252995014
     15		0.011369548738002777
     20		0.010842051357030869

Transformers(Encoder * 4 + Decoder * 4, (32 * 16 * 4)), epochs = 200, lr = 0.0001, batch_size = 32
SNR(dB)		NMSE
    -10		0.030723894014954567
     -5		0.02155248448252678
      0		0.016488781198859215
      5		0.013753222301602364
     10		0.012413587421178818
     15		0.011544693261384964
     20		0.011497770436108112

Transformers(Encoder * 4 + Decoder * 4, (4 * 16 * 32)), epochs = 200, lr = 0.0001, batch_size = 32
SNR(dB)		NMSE
    -10		0.035857681185007095
     -5		0.026454109698534012
      0		0.019532108679413795
      5		0.016106395050883293
     10		0.01433786004781723
     15		0.01295443531125784
     20	        0.012212691828608513

Transformers(Encoder * 4 + Decoder * 4, originnal shape), epochs = 200, lr = 0.0001, batch_size = 32
SNR(dB)		NMSE
    -10		
     -5		
      0		
      5		
     10		
     15		
     20	        
---------------------------------------------------------------------------------------------
Transformers(Encoder * 9 + Decoder * 9, (16 * 32 * 4)), epochs = 200, lr = 0.0001, batch_size = 32
SNR(dB)		NMSE
    -10		
     -5		
      0		
      5		
     10		
     15		
     20		0.11178303509950638
     
Transformers(Encoder * 9 + Decoder * 5, (16 * 32 * 4)), epochs = 200, lr = 0.0001, batch_size = 32
SNR(dB)		NMSE
    -10		
     -5		
      0		
      5		
     10		
     15		
     20		0.10838431864976883

Transformers(Encoder * 6 + Decoder * 4, (16 * 32 * 4)), epochs = 200, lr = 0.0001, batch_size = 32
SNR(dB)		NMSE
    -10		
     -5		
      0		
      5		
     10		
     15		
     20		0.011087425984442234

Transformers(Encoder * 5 + Decoder * 4, (16 * 32 * 4)), epochs = 200, lr = 0.0001, batch_size = 32
SNR(dB)		NMSE
    -10		
     -5		
      0		
      5		
     10		
     15		
     20		0.010988997295498848

Transformers(Encoder * 6 + Decoder * 3, (16 * 32 * 4)), epochs = 200, lr = 0.0001, batch_size = 32
SNR(dB)		NMSE
    -10		
     -5		
      0		
      5		
     10		
     15		
     20		0.011021256446838379

Transformers(Encoder * 4 + Decoder * 5, (16 * 32 * 4)), epochs = 200, lr = 0.0001, batch_size = 32
SNR(dB)		NMSE
    -10		
     -5		
      0		
      5		
     10		
     15		
     20		0.010938742198050022

Transformers(Encoder * 1 + Decoder * 8, (16 * 32 * 4)), epochs = 200, lr = 0.0001, batch_size = 32
SNR(dB)		NMSE
    -10		
     -5		
      0		
      5		
     10		
     15		
     20		0.010868697427213192

Transformers(Encoder * 0 + Decoder * 9, (16 * 32 * 4)), epochs = 200, lr = 0.0001, batch_size = 32
SNR(dB)		NMSE
    -10		
     -5		
      0		
      5		
     10		
     15		
     20		0.010852125473320484

Transformers(Encoder * 5 + Decoder * 5, (16 * 32 * 4)), epochs = 200, lr = 0.0001, batch_size = 32
SNR(dB)		NMSE
    -10		
     -5		
      0		
      5		
     10		
     15		
     20		0.011175029911100864	

Transformers(Encoder * 3 + Decoder * 3, (16 * 32 * 4)), epochs = 200, lr = 0.0001, batch_size = 32
SNR(dB)		NMSE
    -10		
     -5		
      0		
      5		
     10		
     15		
     20		0.010860620066523552
