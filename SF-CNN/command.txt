command:
python3 SF_CNN_2fre_train.py > train1.log 2>&1
python3 SF_CNN_2fre_train_further.py > train2.log 2>&1
python3 SF_CNN_2fre_test.py > test.log 2>&1

GPU: NVIDIA GeForce RTX 3060 Ti
cuda: 12.3
cudnn: 8.9.7
tensorflow: 2.15.0
https://jackfrisht.medium.com/install-nvidia-driver-via-ppa-in-ubuntu-18-04-fc9a8c4658b9


CNN, epochs = 200, lr = 0.0001, batch_size = 128
SNR(dB)		NMSE
    -10		0.8902655945595724
     -5		0.5751199399355023
      0		0.36848606844546833
      5		0.29410193315144156
     10		0.2553683132455284
     15		0.23459051626799857
     20		0.2303461244047422
     
CNN, epochs = 200, lr = 0.0001, batch_size = 32
SNR(dB)		NMSE
    -10		0.810673524905295
     -5		0.4919532945371677
      0		0.2643258475639457
      5		0.16703036852743622
     10		0.11317730937141791
     15		0.09042117733683336
     20		0.07431391089906239
---------------------------------------------------------------------------------------------
Transformers(Encoder, v1), epochs = 40, lr = 0.0001, batch_size = 32
SNR(dB)		NMSE
    -10		0.9770831849262505, 0.8134316863427159
     -5		0.7012182835272307
      0		0.49189052603046274
      5		0.39420415368532674
     10		0.23643466031546911
     15		0.19068080361620274
     20		0.14560928882392193
     
Transformers(Encoder, v1), epochs = 200, lr = 0.0001, batch_size = 32
SNR(dB)		NMSE
    -10		0.9228426684052887
     -5		0.6831239491929525
      0		0.2941315855551049
      5		0.14006600876597874(better than CNN)
     10		0.1021696856387804(better than CNN)
     15		0.06976020783386723(better than CNN)
     20		0.04713466330402714, 0.116335418982825(better than CNN)
---------------------------------------------------------------------------------------------
Transformers(Encoder, new version, (16 * 32 * 4)), epochs = 200, lr = 0.0001, batch_size = 32
SNR(dB)		NMSE
    -10		1.0034997822283107
     -5		1.0022078917963781
      0		0.42036374677900773
      5		0.24588232616118508
     10		0.13356168133422286
     15		0.08693595202165977
     20		0.055574757864449695
     
Transformers(Encoder, new version, (4 * 16 * 32)), epochs = 200, lr = 0.0001, batch_size = 32
SNR(dB)		NMSE
    -10		1.0056178096656145
     -5		1.0051167132633074
      0		1.0047594643512026
      5		1.0135836603921828
     10		1.0049115998872755
     15		0.14973634341748948
     20		0.10742040065425469
     
Transformers(Encoder, new version, (32 * 16 * 4)), epochs = 200, lr = 0.0001, batch_size = 32
SNR(dB)		NMSE
    -10		1.005581103661059
     -5		1.023077848010152
      0		1.0091059088906147
      5		1.0158015911275906
     10		0.13586349671622336
     15		0.0907570120291898
     20		0.052233937396309695
---------------------------------------------------------------------------------------------
Transformers(Encoder, new version, with positional encoder, (16 * 32 * 4)), epochs = 200, lr = 0.0001, batch_size = 32
SNR(dB)		NMSE
    -10		0.030377166345715523
     -5		0.020921865478157997
      0		0.01644887961447239
      5		0.013676438480615616
     10		0.012209874577820301
     15		0.01129317656159401
     20		0.011004100553691387
     
Transformers(Encoder, new version, with positional encoder, (4 * 16 * 32)), epochs = 200, lr = 0.0001, batch_size = 32
SNR(dB)		NMSE
    -10		0.035654228180646896
     -5		0.025894038379192352
      0		0.01961899921298027
      5		0.01625351794064045
     10		0.0141898263245821
     15		0.013078039512038231
     20		0.012580392882227898

Transformers(Encoder, new version, with positional encoder, (32 * 16 * 4)), epochs = 200, lr = 0.0001, batch_size = 32
SNR(dB)		NMSE
    -10		0.030933775007724762
     -5		0.021904414519667625
      0		0.016832156106829643
      5		0.013988425023853779
     10		0.012418906204402447
     15		0.011840230785310268
     20		0.011266968213021755

Transformers(Encoder, new version, with positional encoder, originnal shape), epochs = 200, lr = 0.0001, batch_size = 32
SNR(dB)		NMSE
    -10		0.11000585556030273
     -5		0.05076548457145691
      0		0.04574974998831749
      5		0.02721697837114334
     10		0.02782992459833622
     15		0.028809938579797745
     20		0.022801632061600685

